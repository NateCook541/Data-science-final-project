{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f1782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e058f",
   "metadata": {},
   "source": [
    "# Final project - Nate Cook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dece0ea9",
   "metadata": {},
   "source": [
    "The main question of this notebook is can I predict the amount of arrests per game based on various factors. Some other questions I have is what team has the most average arrests per game, what factors lead to the most arrests, and what day has the most arrests on average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f1e4ec",
   "metadata": {},
   "source": [
    "## 1 - Looking at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa06ed4",
   "metadata": {},
   "source": [
    "### 1.1 - Data Description\n",
    "- `season`: The NFL season year. Int\n",
    "- `week_num`: The week number of the NFL season. Int\n",
    "- `day_of_week`: The day of the week the game was played. String\n",
    "- `gametime_local`: The local time the game started. String\n",
    "- `home_team`: The name of the home team. String\n",
    "- `away_team`: The name of the away team. String\n",
    "- `home_score`: The score of the home team. Int\n",
    "- `away_score`: The score of the away team. Int\n",
    "- `OT_flag`: Indicates if the game went into overtime. String (e.g., \"OT\" or empty)\n",
    "- `arrests`: The number of arrests made during and after the game. Int\n",
    "- `division_game`: Indicates if the game was a divisional matchup. String (e.g., \"y\" or \"n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15da7590",
   "metadata": {},
   "source": [
    "### 1.2 - Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"nfl_arrests_2011-2015.csv\")\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec0cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 10 rows\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1268f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the info of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25262539",
   "metadata": {},
   "source": [
    "From this overview of the data my first big problem appears with the amount of categorical features. There is a heavy amount of categorical data I need to convert, but most of it shouldn't be bad. I could convert the ot flag to 0 if false and 1 if true and do the same for division game. I can convert game time and day to integers as well, but converting teams through one hot encoding might make the data set to large. I need to research some ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe54759",
   "metadata": {},
   "source": [
    "### 1.5 - Check for nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "nulls = df.isnull().sum()\n",
    "print(\"\\nNull values per column:\")\n",
    "print(nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00da4b",
   "metadata": {},
   "source": [
    "A lot of nulls in OT_Flag but that will be fixed in cleaning and arrests will just be filled with mean in cleaning as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aefb8c8",
   "metadata": {},
   "source": [
    "### 1.7 - Finding basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9661b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Games per season\n",
    "print(\"\\nGames per season:\")\n",
    "display(df['season'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce716ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Games per day\n",
    "print(\"\\nGames per day of week:\")\n",
    "display(df['day_of_week'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c3d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean arrests per game\n",
    "print(\"\\nMean arrests per game:\", df['arrests'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd647cc",
   "metadata": {},
   "source": [
    "## 2 - Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a9b67c",
   "metadata": {},
   "source": [
    "This is a hard section for me because I want to fill nulls, convert, add features, and scale them all before I can start to run predications on anything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba8892e",
   "metadata": {},
   "source": [
    "### 2.1 - Fill null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eee47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null ot flag values with N\n",
    "df['OT_flag'] = df['OT_flag'].fillna('N')\n",
    "\n",
    "# Check to see if it worked\n",
    "nulls = df.isnull().sum()\n",
    "print(\"\\nNull values per column:\")\n",
    "print(nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b710a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next fill all numerical features with mean\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[numeric_columns] = imputer.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Check to see if it worked\n",
    "nulls = df.isnull().sum()\n",
    "print(\"\\nNull values per column:\")\n",
    "print(nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92878591",
   "metadata": {},
   "source": [
    "Now all nulls are filled, so now we can start to convert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc68c8ad",
   "metadata": {},
   "source": [
    "### 2.5 - Convert categorical to numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0882cee8",
   "metadata": {},
   "source": [
    "First im going to start with one hot encoding the day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b98a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"day_of_week\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb1fc79",
   "metadata": {},
   "source": [
    "5 Values means 5 features will be add, but it is very annoying that I have to add wednesday as a feature even though it only appears once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c78ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day of week to numerical\n",
    "day_encoder = OneHotEncoder(sparse_output=False)\n",
    "day_encoded = day_encoder.fit_transform(df[['day_of_week']])\n",
    "day_encoded_df = pd.DataFrame(day_encoded, columns=[f'day_{cat}' for cat in day_encoder.categories_[0]])\n",
    "df = pd.concat([df, day_encoded_df], axis=1)\n",
    "df.drop('day_of_week', axis=1, inplace=True)\n",
    "\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a163e9",
   "metadata": {},
   "source": [
    "Next is teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d477a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"home_team\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27649ce1",
   "metadata": {},
   "source": [
    "There is defiantly too many teams here to one hot encode because I have to do away and home. After researching only I think label encoding will work the best out of my options. How this will work is it will assign each home and away team a integer value that will correspond to the team. It shouldn't be to bad to make it work for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87533c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team encoding\n",
    "all_teams = sorted(set(df['home_team'].unique()).union(set(df['away_team'].unique())))\n",
    "team_to_id = {team: idx for idx, team in enumerate(all_teams)}\n",
    "\n",
    "df['home_team_id'] = df['home_team'].map(team_to_id)\n",
    "df['away_team_id'] = df['away_team'].map(team_to_id)\n",
    "df.drop(['home_team', 'away_team'], axis=1, inplace=True)\n",
    "\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa1645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the table of the id with the team\n",
    "team_encoding_df = pd.DataFrame(list(team_to_id.items()), columns=['Team', 'Team_ID'])\n",
    "display(team_encoding_df.sort_values('Team_ID'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7535f6d9",
   "metadata": {},
   "source": [
    "Label encoding worked great here and now I just have to fix a couple more values and I should be done with converting soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cf19ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert OT_flag and division_game to 0 and 1\n",
    "df['overtime'] = df['OT_flag'].apply(lambda x: 1 if x == 'OT' else 0)\n",
    "df.drop('OT_flag', axis=1, inplace=True)\n",
    "\n",
    "# Convert division_game\n",
    "df['division_game'] = df['division_game'].apply(lambda x: 1 if x.lower() == 'y' else 0)\n",
    "\n",
    "# Check if worked\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880bc36d",
   "metadata": {},
   "source": [
    "Lastly I need to convert game time to numerical. This turned out to be pretty hard because I tried to convert to hours and just round, but that didn't work at all and messed up the data anyways. After looking online for a bit I found the re library and a stack overflow question with basically the same problem and just used the function in there and it worked great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a2929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert game time\n",
    "def time_to_minutes(time_str):\n",
    "    match = re.search(r'(\\d+):(\\d+):(\\d+)\\s*([AP]M)', time_str)\n",
    "    if match:\n",
    "        hour, minute, second, period = match.groups()\n",
    "        hour = int(hour)\n",
    "        if period == 'PM' and hour < 12:\n",
    "            hour += 12\n",
    "        elif period == 'AM' and hour == 12:\n",
    "            hour = 0\n",
    "        return hour * 60 + int(minute)\n",
    "    return None\n",
    "\n",
    "df['game_minutes'] = df['gametime_local'].apply(time_to_minutes)\n",
    "df.drop('gametime_local', axis=1, inplace=True)\n",
    "\n",
    "# Check if worked\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80b0f07",
   "metadata": {},
   "source": [
    "Now after all the conversion I got every feature to numerical and I didn't have to use one hot encoding much so the data set isn't extremely big either. Now I want to add a couple more features to help the future analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede098c",
   "metadata": {},
   "source": [
    "### 2.7 - Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b49293",
   "metadata": {},
   "source": [
    "For the features I decided I want to add I went with total points, score difference, home team win, high scoring, and game competitiveness all of which will be explained in more code comments when in their cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First is total points which is just home + away points added together\n",
    "df['total_points'] = df['home_score'] + df['away_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706933b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next is score difference which is the difference between the two teams scoring\n",
    "df['score_diff'] = df['home_score'] - df['away_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e22462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now home team win is added which is just seeing whether the home team won and if they did a 1 is recorded and if not a 0 is recorded\n",
    "df['home_win'] = (df['score_diff'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823eb57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next is high scoring which finds the average score of the games and if it is above records a 1 and if not it records a 0\n",
    "median_score = df['total_points'].median()\n",
    "df['high_scoring'] = (df['total_points'] > median_score).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f16ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly is game competitiveness which uses how close the score was to find if they game was competitive\n",
    "df['competitive_game'] = 1 - (abs(df['score_diff']) / df['total_points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68127d86",
   "metadata": {},
   "source": [
    "Now we can check if they all worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db357c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43117978",
   "metadata": {},
   "source": [
    "It looks perfect and now that those features are added its finally time to scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b2e4a1",
   "metadata": {},
   "source": [
    "### 2.7 - Splitting and Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861db632",
   "metadata": {},
   "source": [
    "I forgot I need to split my data before so im going to do that quickly and then scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0279932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable and features\n",
    "y = df['arrests']\n",
    "X = df.drop('arrests', axis=1)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cbdf69",
   "metadata": {},
   "source": [
    "Now I can actually scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d621f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which ones to scale because no point in scale the 0 and 1 columns\n",
    "cols_to_scale = ['season', 'week_num', 'home_score', 'away_score', \n",
    "                'game_minutes', 'total_points', 'score_diff', 'competitive_game']\n",
    "\n",
    "# Create and fit scaler using training data\n",
    "scaler = StandardScaler()\n",
    "X_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "\n",
    "# Apply the same to the test data\n",
    "X_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac5b538",
   "metadata": {},
   "source": [
    "Now that the training and test data is scaled I can output the head for each and see if I can finally be done with cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final training data after cleaning: \")\n",
    "display(X_train.head(3))\n",
    "\n",
    "print(\"Final test data after cleaning: \")\n",
    "display(X_test.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb132c55",
   "metadata": {},
   "source": [
    "It looks good and now I am finally done with cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b079f8c9",
   "metadata": {},
   "source": [
    "A quick summary of what I did with part 2 was I filled all nulls, converted all categorical data to numerical with one hot encoding and label encoding, I split the data into test and training data and made sure my target (arrests) was not included, I also added 5 new features to help with future analysis, and lastly I scaled both the test and training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009dfab6",
   "metadata": {},
   "source": [
    "## 3 - Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9228f85b",
   "metadata": {},
   "source": [
    "### 3.1 - Feature correlation and Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d316112",
   "metadata": {},
   "source": [
    "Firstly, I want to look at the target variable more closely to help my future predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2978a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize arrests\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_train, bins=20, edgecolor='black')\n",
    "plt.title('Distribution of Arrests')\n",
    "plt.xlabel('Number of Arrests')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df167bc",
   "metadata": {},
   "source": [
    "From the graph you can see the mass majority of the arrests fall into the 0 - 10 range. This will be important in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aae279",
   "metadata": {},
   "source": [
    "Next, I want to make a feature correlation to see which features impact it the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4383df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the correlation matrix and the features\n",
    "correlation_matrix = pd.concat([X_train, y_train], axis=1).corr()\n",
    "top_features = correlation_matrix['arrests'].abs().sort_values(ascending=False)[1:11].index.tolist()\n",
    "top_corr = correlation_matrix.loc[top_features + ['arrests'], top_features + ['arrests']]\n",
    "\n",
    "# Plot it\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(top_corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap: Top 10 Features vs Arrests')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbb62ab",
   "metadata": {},
   "source": [
    "From this graph you can see a lot of interesting features. Home team winning, total points, game minutes, and away score lead to a lot of violence the more they increase. While oddly Sunday seems to see a lot less arrests than Monday games for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432673d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = X_train.corr()\n",
    "target_correlations = pd.concat([X_train, y_train], axis=1).corr()['arrests'].sort_values(key=abs, ascending=False)\n",
    "print(\"Features most correlated with arrests:\")\n",
    "print(target_correlations[1:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf39f10",
   "metadata": {},
   "source": [
    "Now after learning more about the data and features im ready to start with training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa82f7",
   "metadata": {},
   "source": [
    "### 3.5 - Linear regression first attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bec136",
   "metadata": {},
   "source": [
    "Im going to start with linear regression and depending on how it does I wil try and improve or change to a different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cf86fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "print(\"Linear Regression Results:\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_test, lr_pred):.3f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, lr_pred):.3f}\")\n",
    "print(f\"R2: {r2_score(y_test, lr_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a20a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.scatterplot(x=y_test, y=lr_pred, alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Perfect Prediction')\n",
    "plt.xlabel('Actual Arrests')\n",
    "plt.ylabel('Predicted Arrests')\n",
    "plt.title('Actual vs Predicted Arrests (Linear Regression)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971a4c65",
   "metadata": {},
   "source": [
    "Linear regression definitely doesn't work. Im going to try random forest to see if that can help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84151582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_test, rf_pred):.3f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, rf_pred):.3f}\")\n",
    "print(f\"R²: {r2_score(y_test, rf_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce873a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "sns.scatterplot(x=y_test, y=rf_pred, alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Perfect Prediction')\n",
    "plt.xlabel('Actual Arrests')\n",
    "plt.ylabel('Predicted Arrests')\n",
    "plt.title('Actual vs Predicted Arrests (Random forest)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc0e74",
   "metadata": {},
   "source": [
    "Trying to use regression on this data clearly won't work, so instead im going to try to split the arrests into low arrests games and high arrests games and then predict on these separate category's."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4648301f",
   "metadata": {},
   "source": [
    "### 3.7 - More attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff82d0",
   "metadata": {},
   "source": [
    "So to make two separate category's I need to create labels of what a high arrest game is, and I will be going with above the 75th percentile. Then I just split the games into the high vs normal depending on where they fall in the quantile range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba11623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the threshold and split the training and test sets\n",
    "high_arrest_threshold = y_train.quantile(0.75)\n",
    "y_train_class = (y_train > high_arrest_threshold).astype(int)\n",
    "y_test_class = (y_test > high_arrest_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1295f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test games into their groups\n",
    "normal_games = X_test[y_test_class == 0].copy()\n",
    "high_arrest_games = X_test[y_test_class == 1].copy()\n",
    "\n",
    "# Add arrests for reference\n",
    "normal_games['arrests'] = y_test[y_test_class == 0]\n",
    "high_arrest_games['arrests'] = y_test[y_test_class == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f845fa",
   "metadata": {},
   "source": [
    "Perfect, now im going to predict on normal and high separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908283d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use split based on the threshold\n",
    "normal_test_idx = y_test_class == 0\n",
    "high_test_idx = y_test_class == 1\n",
    "\n",
    "# Make a prediction on both normal and high games\n",
    "arrest_pred = np.zeros_like(y_test, dtype=float)\n",
    "arrest_pred[normal_test_idx] = reg_normal.predict(X_test[normal_test_idx])\n",
    "arrest_pred[high_test_idx] = reg_high.predict(X_test[high_test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44998a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class labels for test set\n",
    "normal_mask = y_test_class == 0\n",
    "high_mask = y_test_class == 1\n",
    "\n",
    "print(\"Normal Games Regression Results:\")\n",
    "print(f\"  RMSE: {root_mean_squared_error(y_test[normal_mask], arrest_pred[normal_mask]):.3f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test[normal_mask], arrest_pred[normal_mask]):.3f}\")\n",
    "print(f\"  R2: {r2_score(y_test[normal_mask], arrest_pred[normal_mask]):.3f}\")\n",
    "\n",
    "print(\"\\nHigh-Arrest Games Regression Results:\")\n",
    "print(f\"  RMSE: {root_mean_squared_error(y_test[high_mask], arrest_pred[high_mask]):.3f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test[high_mask], arrest_pred[high_mask]):.3f}\")\n",
    "print(f\"  R2: {r2_score(y_test[high_mask], arrest_pred[high_mask]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# Normal games\n",
    "axes[0].scatter(y_test[normal_mask], arrest_pred[normal_mask], alpha=0.7, color='blue')\n",
    "axes[0].plot([y_test[normal_mask].min(), y_test[normal_mask].max()],\n",
    "             [y_test[normal_mask].min(), y_test[normal_mask].max()],\n",
    "             'r--', label='Perfect Prediction')\n",
    "axes[0].set_title('Normal Games')\n",
    "axes[0].set_xlabel('Actual Arrests')\n",
    "axes[0].set_ylabel('Predicted Arrests')\n",
    "axes[0].legend()\n",
    "\n",
    "# High-Arrest games\n",
    "axes[1].scatter(y_test[high_mask], arrest_pred[high_mask], alpha=0.7, color='orange')\n",
    "axes[1].plot([y_test[high_mask].min(), y_test[high_mask].max()],\n",
    "             [y_test[high_mask].min(), y_test[high_mask].max()],\n",
    "             'r--', label='Perfect Prediction')\n",
    "axes[1].set_title('High-Arrest Games')\n",
    "axes[1].set_xlabel('Actual Arrests')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.suptitle('Actual vs Predicted Arrests by Game Category')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cea0b6",
   "metadata": {},
   "source": [
    "The problem still exists of outliers skewing the prediction to much and ive accepted that arrests is not really predictable with the data in the dataset. No feature on amount of attendance, No weather data (Worse weather likely leads to less arrests), if the game is a playoff game, etc. Instead I will switch from trying to predict amount of arrests to a classification of if a game will be high arrest or a normal amount of arrests. This will be similar to how I split the data because im defining a high arrest game above the 75th percentile, but I will then need to actually predict. Also I will be using random forest's classifier for the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca85b6",
   "metadata": {},
   "source": [
    "### 3.9 - Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the high arrest games (75th percentile)\n",
    "high_arrest_threshold = y_train.quantile(0.75)\n",
    "print(f\"High-arrest threshold: {high_arrest_threshold}\")\n",
    "\n",
    "# Create binary target\n",
    "y_train_class = (y_train > high_arrest_threshold).astype(int)\n",
    "y_test_class = (y_test > high_arrest_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4facb8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction using random forest\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train_class)\n",
    "y_pred_class = clf.predict(X_test)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Classification Report (Normal vs High-Arrest):\")\n",
    "print(classification_report(y_test_class, y_pred_class, target_names=[\"Normal\", \"High-Arrest\"]))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad289a",
   "metadata": {},
   "source": [
    "Im kind of happy with the classification report as it shows scores in the 90s for normal, but its high arrest scores are in the 70s range. This shows that it can predict a normal amount of arrests with my factors very well but struggles a bit for high arrests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab19af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix graph\n",
    "cm = confusion_matrix(y_test_class, y_pred_class)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Normal\", \"High-Arrest\"], yticklabels=[\"Normal\", \"High-Arrest\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix: Normal vs High-Arrest Games\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e9f2cb",
   "metadata": {},
   "source": [
    "Im kind of happy with the confusion matrix results with the good results for normal, but has some issues with high arrests games. It seems to be predicting most games to be normal (20 false negatives). Next im going to try and work on improving these results a bit to get better results for high arrests games."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd92adc4",
   "metadata": {},
   "source": [
    "## 4 - Final improvements and further questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
